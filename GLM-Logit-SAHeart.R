rm(list=ls(all=TRUE))
library(plyr)
library(ggplot2)
setwd('/Users/zurich/Google Drive/FactMachine-SITE/FM-Site-STRUCTURE/13-LogisticRegression')

#=======================================
# Data preparation section

dfSA <- read.csv("SAHeart.csv")
dfSA$row.names <- NULL
# recode 0,1 as true / false
chdVector <- mapvalues(dfSA$chd, from = c(0,1), to = c("FALSE", "TRUE"))
dfSA$chd <- as.logical(chdVector)

# create vectors for k folds, where k = 5
numberOfFolds <- 5
set.seed(12)
# create a vector length(DataFrame) consisting of elements from 1:k
kFolds <- sample(1:numberOfFolds, nrow(dfSA), replace = TRUE)

# create blank lists:
# lstProbs contains probabilities generated by model applied to test data
lstProbs <- list()
# lstTestData contains T or F actual values of the test data
lstTestData <- list()
# fold names will be the list elements "fold1"...'foldk'
foldNames <- paste("fold", 1:numberOfFolds, sep="")

# set up single column matrix of probabilities
# create a vector 0.01 to 0.99 (99 elements)
threshSeq <- seq(from = 0.01, to = 0.99, by = 0.01)
# create the 99 x 1 matrix
matProb <- matrix(threshSeq, nrow = length(threshSeq))
# assign colname and then rownames to the matrix
colnames(matProb) <- "prob"; rownames(matProb) <- seq(1:length(threshSeq))

#=======================================
# Modelling section

# create k different models and then create predictions based on test sets
for (k in 1:numberOfFolds) {
  # iterate through the numberOfFolds. 5 folds in this case.
  # fit logit regression using all predictor variables 'chd' is dependent variable
  # fitted model uses training data. i.e. [kFolds != k,] 
  fittedModel <- glm(chd ~., data=dfSA[kFolds != k,], family=binomial)
  # predict function uses fitted model to predict probabilites.
  # this uses test data: [kFolds == k,]
  predProbs <- predict(fittedModel, newdata=dfSA[kFolds == k,], type = "response")
  # lstProbs contains 5 main element: 'fold1' ...'foldk' these folds will have a slightly different length
  lstProbs[[foldNames[k]]] <- predProbs
  lstTestData[[foldNames[k]]] <- dfSA[kFolds == k, "chd"]
  # assert sameDimenstions(lstTestData, lstTestData) == TRUE 
}

#=======================================
# following are calculations for overall accuracy of the logit model

fnCalcAccuracy <- function(probability) {
  # this function is called by apply(). The function is called repeatedly.
  # each time the function is called a different probability is called.
  
  #lstProbs is converted to lstBlnPredict, based on the current probability
  lstBlnPredict <- lapply(lstProbs, function(x) ifelse(x > probability, T, F))
  # following returns 1 x 5 vector  Result is run for each probability
  # This creates a 5 (fold) x 1 (probability) vector for each iteration 
  vectAccuracy <- mapply(function(x, y) {mean(x == y)}, lstBlnPredict, lstTestData)
  # After the 99 iterations (5 x 1) vectors are assembled into a 5 x 99 matrix by apply()
}

# t(5 x 99) becomes (99 x 5) matrix
matAccuracy <- t(apply(matProb, 1, fnCalcAccuracy))
rownames(matAccuracy) <- threshSeq
# vctAccuracy = 1 x  99 vector
vctAccuracy <- apply(matAccuracy, 1, mean)

#=======================================
# following are calculations for Recall

fnCalcRecall <- function(probability) {
  # this fuction operates exactly the same as fnCalcAccuracy except the mapply call..
  # ..has a different function. Two functions have could be refactored into a single..
  # ..function with a function as an argument.
  lstBlnPredict <- lapply(lstProbs, function(x) ifelse(x > probability, T, F))
  vectRecall <- mapply(function(pred, actual){ sum(pred & actual) / sum(actual) }, 
                            lstBlnPredict, lstTestData )
}

matRecall <- t(apply(matProb, 1, fnCalcRecall))
rownames(matRecall) <- threshSeq
vctRecall <- apply(matRecall, 1, mean)

#=======================================
# following are calculations for Precision

fnCalcPrecision <- function(probability) {
  # returns a fold1 ... fold 5 list of booleans. These are the predictions given a specific probability
  lstBlnPredict <- lapply(lstProbs, function(x) ifelse(x > probability, T, F))
  # following returns 1 x 5 vector  Result is run for each probability
  # This creates |probability| x nFold matrix
  vectRecall <- mapply(function(pred, actual){ sum(pred & actual) / sum(pred) }, 
                       lstBlnPredict, lstTestData )
}

matPrecision <- t(apply(matProb, 1, fnCalcPrecision))
rownames(matPrecision) <- threshSeq
vctPrecision <- apply(matPrecision, 1, mean)
#set NaN's to 1..bit of hack here. NaN's result of divide by zero error
vctPrecision <- ifelse(is.na(vctPrecision), 1, vctPrecision)


# Assemble accuracy, recall & precision into a dataframe
dfThold <- data.frame(tHold = threshSeq, accuracy = vctAccuracy, 
                      recall = vctRecall, precision = vctPrecision)

#=======================================
# GGPlot2 Section

lineSize = 1
plot <- ggplot(dfThold, aes(tHold)) 
plot <- plot + geom_line(aes(y = accuracy), colour = '#FF0000', size = lineSize /2)
plot <- plot + geom_line(aes(y = recall), colour = '#00CC00', size = lineSize)
plot <- plot + geom_line(aes(y = precision), colour = '#0000CC', size = lineSize)
plot <- plot + coord_fixed()
plot

# Can (un)comment the following to save the graph to file
# ggsave(file = "precisionRecallA.pdf",  useDingbats=FALSE)

#=======================================
# Create two tables for T = 0.50 and T = 0.25

# Creates list with 5 logical vectors

lstBlnPredict050 <- lapply(lstProbs, function(x) ifelse(x > 0.50, T, F))
print("table elements for threshold 0.50")
apply(mapply(table, lstBlnPredict050, lstTestData),1, sum)

lstBlnPredict025 <- lapply(lstProbs, function(x) ifelse(x > 0.25, T, F))
print("table elements for threshold 0.25")
apply(mapply(table, lstBlnPredict025, lstTestData),1, sum)


















